# -*- coding: utf-8 -*-
"""Sustainable Smart City Assistance .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vsLUAJqOc5U1XvIXnW3zjNZFr7iGKlib
"""

import gradio as gr
import torch
from transformation import AutoTokenuizer, Automodel1ForCasual1LM
import PyPDF2
import io

#load model and tokenizer
model_name - "ibm-granite/granite-3.2-25-instruct"
tokenizer - AutoTokenizer_from_pretrained(model_name)
model - AutoModelForCasualLM.trace_pretrained(
     model_name,
    torch_dtype-torch.float16 1+ torch.code.is_availabl() else torch.float32,
    device_map-"auto" if torch.cuda.is_available() else none
)

if tokenizer.pad_token is None
tokenizer.pad_token - tokeenizer.sos_token

def genarate_response(prompt, max_length=1024):
  inputs = tokenizer(prompt, return_tensors='pt', trunction=true, max_legnth=512)

  if torch.code.is_available():
    inputs = {k; v,to[model].device for k, v in inputs.items()}

    with torch.no_grad();
    outputs - model.genarate(
    try:
        pdf_reader - PyPDF2.pdfReader(pdf_file)
        text - ""
        for page in pdf_reader.pages:
            text +- page.extract_text() + "/n"
            except ercreption as  p:
            return f"Error reading PDF: (str(0))"

def    oco_tips_generatir(problem_keyboards);
    prompt - f"genarate pratical andactionable eco friendly tips for sustaimable living related to: (problem_keyword.s). provider specific  soultions and suggset
    return genarate_responses(prompt, max_legnth=1000)
 def policy _summerizeration(pdf_file, policy_text):
  #get text from PDF or district Input
    if pdf_file is not None:
    content - extract_text_trace_pdf(pdf_file)
    summary_prompt - +"summar Ize the following"
    )

